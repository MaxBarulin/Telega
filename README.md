# Telegram LLM Bridge

Проект представляет собой интеграцию между мессенджером Telegram и локальной языковой моделью (LLM), запущенной через KoboldCPP. Основная цель — автоматизация ответов в диалогах с возможностью модерации (Human-in-the-loop).

## Основной функционал

*   **Мониторинг сообщений**: Отслеживание новых сообщений в выбранном чате или диалоге.
*   **Генерация ответов**: Использование локальной нейросети (KoboldCPP) или облачной модели Google Gemini для создания ответов.
*   **Режимы работы**:
    *   **Ручной (Human-in-the-loop)**: Подтверждение каждого ответа перед отправкой.
    *   **Автоматический**: Мгновенная отправка сгенерированных ответов без участия пользователя.
*   **Сохранение контекста**: Учет истории переписки для более точной генерации.

## Требования

*   Python 3.8+
*   Запущенный экземпляр KoboldCPP (API доступен по адресу `http://localhost:5001`)
*   Учетные данные API Telegram (APP_ID и API_HASH)

## Установка

1.  Клонируйте репозиторий.
2.  Установите необходимые зависимости:

```bash
pip install -r requirements.txt
```

*Примечание: Убедитесь, что установлены `telethon`, `fastapi`, `uvicorn`, `python-dotenv` и `aiohttp`.*

3.  Создайте файл `.env` в корне проекта на основе `.env.example` и заполните следующие поля:

```ini
TELEGRAM_API_ID=ваш_api_id
TELEGRAM_API_HASH=ваш_api_hash
TELEGRAM_SESSION_STRING=строка_сессии (опционально, если есть)
TELEGRAM_SESSION_NAME=имя_файла_сессии
```

## Использование

### Клиент с LLM

Для запуска интерактивного клиента используйте команду:

```bash
python telegram_llm_client.py
```

1.  При запуске скрипт предложит выбрать чат из списка последних диалогов или ввести username/ID вручную.
2.  **Выбор режима**: Вас спросят, включить ли автоматический режим (`Enable fully automatic mode?`).
    *   `y`: Ответы будут отправляться сразу же после генерации.
    *   `N` (по умолчанию): Вы сможете проверить каждый ответ.
3.  После выбора чата скрипт перейдет в режим ожидания сообщений.
4.  При получении сообщения будет сгенерирован вариант ответа.
5.  Доступные действия (в ручном режиме):
    *   **Enter** или **S**: Отправить предложенный ответ.
    *   **E**: Редактировать ответ вручную.
    *   **I**: Пропустить сообщение (ничего не отправлять).

### HTTP API (Опционально)

Файл `telegram_api.py` содержит реализацию HTTP-моста к Telegram через FastAPI. Может использоваться для интеграции с другими внешними системами.

```bash
python telegram_api.py
```

API будет доступно по адресу `http://localhost:8765`. Документация Swagger UI доступна по адресу `/docs`.

## Структура проекта

*   `telegram_llm_client.py`: Основной скрипт для взаимодействия с LLM и пользователем.
*   `telegram_api.py`: Сервер FastAPI для управления клиентом Telegram через HTTP.
*   `.env`: Файл конфигурации (не распространяется в репозитории).
